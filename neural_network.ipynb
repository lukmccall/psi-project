{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional, SpatialDropout1D\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import W2V_MODEL_PATH, PREPROCESSED_TEST_PATH, PREPROCESSED_TRAIN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(PREPROCESSED_TRAIN_PATH)\n",
    "df_test = pd.read_pickle(PREPROCESSED_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytywanie w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(W2V_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odzielanie danych od labeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train.target.to_numpy().reshape(-1,1)\n",
    "Y_test = df_test.target.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeszcze musimy zamienić lity tekst na tokeny. W tym celu skorzystamy z klasy __Tokenizera__ z `kerasa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen = 50)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (1280000, 50)\n",
      "Y_train (1280000, 1)\n",
      "\n",
      "X_test (320000, 50)\n",
      "Y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"Y_train\", Y_train.shape)\n",
    "print()\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"Y_test\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,   77,   41,\n",
       "        240,   25,  256, 2426,   77,   41])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer():\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    embedding_matrix = np.zeros((vocab_size, 300))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[i] = w2v_model.wv[word]\n",
    "    return Embedding(vocab_size, 300, weights = [embedding_matrix], input_length = 50, trainable = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on GPU...\") if tensorflow.config.list_physical_devices('GPU') else print(\"Training on CPU...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM_V1\n",
    "- własny embedding\n",
    "- LSTM 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"LSTM_V1\")\n",
    "model.add(create_embedding_layer())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM_V2\n",
    "- własny embedding\n",
    "- convy\n",
    "- dwukierunkowy LSTM 64\n",
    "- największy dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"LSTM_V2\")\n",
    "model.add(create_embedding_layer())\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM_V3\n",
    "- embedding uczony na bierząco\n",
    "- LSTM 50\n",
    "- najmniejsza sieć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"LSTM_V3\")\n",
    "model.add(Embedding((len(tokenizer.word_index) + 1), 32, input_length=50))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152000 samples, validate on 128000 samples\n",
      "Epoch 1/30\n",
      "1152000/1152000 [==============================] - 240s 208us/step - loss: 0.5255 - accuracy: 0.7360 - val_loss: 0.4803 - val_accuracy: 0.7694\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukMcCall\\anaconda3\\envs\\sentimental140\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4991 - accuracy: 0.7533 - val_loss: 0.4692 - val_accuracy: 0.7751\n",
      "Epoch 3/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4897 - accuracy: 0.7595 - val_loss: 0.4637 - val_accuracy: 0.7775\n",
      "Epoch 4/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4834 - accuracy: 0.7640 - val_loss: 0.4573 - val_accuracy: 0.7823\n",
      "Epoch 5/30\n",
      "1152000/1152000 [==============================] - 239s 207us/step - loss: 0.4789 - accuracy: 0.7670 - val_loss: 0.4551 - val_accuracy: 0.7840\n",
      "Epoch 6/30\n",
      "1152000/1152000 [==============================] - 239s 207us/step - loss: 0.4750 - accuracy: 0.7694 - val_loss: 0.4522 - val_accuracy: 0.7847\n",
      "Epoch 7/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4722 - accuracy: 0.7715 - val_loss: 0.4501 - val_accuracy: 0.7866\n",
      "Epoch 8/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4699 - accuracy: 0.7728 - val_loss: 0.4499 - val_accuracy: 0.7862\n",
      "Epoch 9/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4675 - accuracy: 0.7745 - val_loss: 0.4451 - val_accuracy: 0.7891\n",
      "Epoch 10/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4659 - accuracy: 0.7754 - val_loss: 0.4463 - val_accuracy: 0.7879\n",
      "Epoch 11/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4644 - accuracy: 0.7758 - val_loss: 0.4433 - val_accuracy: 0.7902\n",
      "Epoch 12/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4625 - accuracy: 0.7776 - val_loss: 0.4442 - val_accuracy: 0.7895\n",
      "Epoch 13/30\n",
      "1152000/1152000 [==============================] - 239s 207us/step - loss: 0.4613 - accuracy: 0.7779 - val_loss: 0.4426 - val_accuracy: 0.7913\n",
      "Epoch 14/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4602 - accuracy: 0.7789 - val_loss: 0.4405 - val_accuracy: 0.7924\n",
      "Epoch 15/30\n",
      "1152000/1152000 [==============================] - 239s 207us/step - loss: 0.4591 - accuracy: 0.7798 - val_loss: 0.4405 - val_accuracy: 0.7920\n",
      "Epoch 16/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4581 - accuracy: 0.7802 - val_loss: 0.4405 - val_accuracy: 0.7920\n",
      "Epoch 17/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4571 - accuracy: 0.7811 - val_loss: 0.4380 - val_accuracy: 0.7930\n",
      "Epoch 18/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4565 - accuracy: 0.7813 - val_loss: 0.4389 - val_accuracy: 0.7935\n",
      "Epoch 19/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4554 - accuracy: 0.7817 - val_loss: 0.4392 - val_accuracy: 0.7924\n",
      "Epoch 20/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4546 - accuracy: 0.7824 - val_loss: 0.4372 - val_accuracy: 0.7935\n",
      "Epoch 21/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4542 - accuracy: 0.7827 - val_loss: 0.4370 - val_accuracy: 0.7938\n",
      "Epoch 22/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4535 - accuracy: 0.7831 - val_loss: 0.4364 - val_accuracy: 0.7940\n",
      "Epoch 23/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4528 - accuracy: 0.7835 - val_loss: 0.4365 - val_accuracy: 0.7945\n",
      "Epoch 24/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4524 - accuracy: 0.7837 - val_loss: 0.4359 - val_accuracy: 0.7951\n",
      "Epoch 25/30\n",
      "1152000/1152000 [==============================] - 239s 207us/step - loss: 0.4517 - accuracy: 0.7840 - val_loss: 0.4360 - val_accuracy: 0.7946\n",
      "Epoch 26/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4513 - accuracy: 0.7846 - val_loss: 0.4362 - val_accuracy: 0.7948\n",
      "Epoch 27/30\n",
      "1152000/1152000 [==============================] - 240s 208us/step - loss: 0.4506 - accuracy: 0.7846 - val_loss: 0.4360 - val_accuracy: 0.7954\n",
      "Epoch 28/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4502 - accuracy: 0.7854 - val_loss: 0.4350 - val_accuracy: 0.7957\n",
      "Epoch 29/30\n",
      "1152000/1152000 [==============================] - 239s 208us/step - loss: 0.4499 - accuracy: 0.7854 - val_loss: 0.4349 - val_accuracy: 0.7961\n",
      "Epoch 30/30\n",
      "1152000/1152000 [==============================] - 242s 210us/step - loss: 0.4495 - accuracy: 0.7854 - val_loss: 0.4341 - val_accuracy: 0.7966\n",
      "Train on 1152000 samples, validate on 128000 samples\n",
      "Epoch 1/30\n",
      "1152000/1152000 [==============================] - 403s 350us/step - loss: 0.4874 - accuracy: 0.7624 - val_loss: 0.4579 - val_accuracy: 0.7825\n",
      "Epoch 2/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4660 - accuracy: 0.7769 - val_loss: 0.4529 - val_accuracy: 0.7864\n",
      "Epoch 3/30\n",
      "1152000/1152000 [==============================] - 400s 347us/step - loss: 0.4592 - accuracy: 0.7808 - val_loss: 0.4490 - val_accuracy: 0.7869\n",
      "Epoch 4/30\n",
      "1152000/1152000 [==============================] - 401s 349us/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.4459 - val_accuracy: 0.7897\n",
      "Epoch 5/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4516 - accuracy: 0.7850 - val_loss: 0.4450 - val_accuracy: 0.7904\n",
      "Epoch 6/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4489 - accuracy: 0.7872 - val_loss: 0.4441 - val_accuracy: 0.7906\n",
      "Epoch 7/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.4443 - val_accuracy: 0.7912\n",
      "Epoch 8/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4458 - accuracy: 0.7884 - val_loss: 0.4423 - val_accuracy: 0.7916\n",
      "Epoch 9/30\n",
      "1152000/1152000 [==============================] - 400s 348us/step - loss: 0.4443 - accuracy: 0.7896 - val_loss: 0.4430 - val_accuracy: 0.7923\n",
      "Epoch 10/30\n",
      "1152000/1152000 [==============================] - 401s 349us/step - loss: 0.4428 - accuracy: 0.7904 - val_loss: 0.4421 - val_accuracy: 0.7914\n",
      "Epoch 11/30\n",
      "1152000/1152000 [==============================] - 402s 349us/step - loss: 0.4417 - accuracy: 0.7910 - val_loss: 0.4435 - val_accuracy: 0.7916\n",
      "Epoch 12/30\n",
      "1152000/1152000 [==============================] - 402s 349us/step - loss: 0.4409 - accuracy: 0.7909 - val_loss: 0.4410 - val_accuracy: 0.7922\n",
      "Epoch 13/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4403 - val_accuracy: 0.7927\n",
      "Epoch 14/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4393 - accuracy: 0.7919 - val_loss: 0.4409 - val_accuracy: 0.7923\n",
      "Epoch 15/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4387 - accuracy: 0.7925 - val_loss: 0.4406 - val_accuracy: 0.7927\n",
      "Epoch 16/30\n",
      "1152000/1152000 [==============================] - 402s 349us/step - loss: 0.4375 - accuracy: 0.7937 - val_loss: 0.4399 - val_accuracy: 0.7938\n",
      "Epoch 17/30\n",
      "1152000/1152000 [==============================] - 401s 349us/step - loss: 0.4368 - accuracy: 0.7938 - val_loss: 0.4393 - val_accuracy: 0.7933\n",
      "Epoch 18/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4365 - accuracy: 0.7940 - val_loss: 0.4402 - val_accuracy: 0.7927\n",
      "Epoch 19/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4356 - accuracy: 0.7946 - val_loss: 0.4393 - val_accuracy: 0.7933\n",
      "Epoch 20/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4357 - accuracy: 0.7946 - val_loss: 0.4391 - val_accuracy: 0.7934\n",
      "Epoch 21/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4350 - accuracy: 0.7949 - val_loss: 0.4396 - val_accuracy: 0.7938\n",
      "Epoch 22/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4344 - accuracy: 0.7949 - val_loss: 0.4395 - val_accuracy: 0.7928\n",
      "Epoch 23/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4340 - accuracy: 0.7953 - val_loss: 0.4387 - val_accuracy: 0.7938\n",
      "Epoch 24/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4332 - accuracy: 0.7959 - val_loss: 0.4391 - val_accuracy: 0.7935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4331 - accuracy: 0.7959 - val_loss: 0.4381 - val_accuracy: 0.7939\n",
      "Epoch 26/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4323 - accuracy: 0.7963 - val_loss: 0.4383 - val_accuracy: 0.7938\n",
      "Epoch 27/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4323 - accuracy: 0.7962 - val_loss: 0.4388 - val_accuracy: 0.7944\n",
      "Epoch 28/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4321 - accuracy: 0.7963 - val_loss: 0.4388 - val_accuracy: 0.7946\n",
      "Epoch 29/30\n",
      "1152000/1152000 [==============================] - 402s 349us/step - loss: 0.4319 - accuracy: 0.7966 - val_loss: 0.4391 - val_accuracy: 0.7931\n",
      "Epoch 30/30\n",
      "1152000/1152000 [==============================] - 401s 348us/step - loss: 0.4312 - accuracy: 0.7970 - val_loss: 0.4384 - val_accuracy: 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukMcCall\\anaconda3\\envs\\sentimental140\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152000 samples, validate on 128000 samples\n",
      "Epoch 1/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.5035 - accuracy: 0.7562 - val_loss: 0.4673 - val_accuracy: 0.7800\n",
      "Epoch 2/30\n",
      "1152000/1152000 [==============================] - 216s 187us/step - loss: 0.4590 - accuracy: 0.7867 - val_loss: 0.4614 - val_accuracy: 0.7826\n",
      "Epoch 3/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.4435 - accuracy: 0.7947 - val_loss: 0.4598 - val_accuracy: 0.7821\n",
      "Epoch 4/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.4322 - accuracy: 0.8007 - val_loss: 0.4594 - val_accuracy: 0.7818\n",
      "Epoch 5/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.4230 - accuracy: 0.8055 - val_loss: 0.4608 - val_accuracy: 0.7823\n",
      "Epoch 6/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.4150 - accuracy: 0.8091 - val_loss: 0.4633 - val_accuracy: 0.7818\n",
      "Epoch 7/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.4090 - accuracy: 0.8122 - val_loss: 0.4657 - val_accuracy: 0.7823\n",
      "Epoch 8/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.4036 - accuracy: 0.8148 - val_loss: 0.4691 - val_accuracy: 0.7816\n",
      "Epoch 9/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.3986 - accuracy: 0.8171 - val_loss: 0.4707 - val_accuracy: 0.7809\n",
      "Epoch 10/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3867 - accuracy: 0.8239 - val_loss: 0.4754 - val_accuracy: 0.7811\n",
      "Epoch 11/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3850 - accuracy: 0.8245 - val_loss: 0.4766 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "1152000/1152000 [==============================] - 216s 188us/step - loss: 0.3840 - accuracy: 0.8250 - val_loss: 0.4790 - val_accuracy: 0.7810\n",
      "Epoch 13/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3826 - accuracy: 0.8257 - val_loss: 0.4805 - val_accuracy: 0.7810\n",
      "Epoch 14/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3819 - accuracy: 0.8260 - val_loss: 0.4805 - val_accuracy: 0.7808\n",
      "Epoch 15/30\n",
      "1152000/1152000 [==============================] - 216s 187us/step - loss: 0.3800 - accuracy: 0.8270 - val_loss: 0.4801 - val_accuracy: 0.7808\n",
      "Epoch 16/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3798 - accuracy: 0.8269 - val_loss: 0.4803 - val_accuracy: 0.7809\n",
      "Epoch 17/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3796 - accuracy: 0.8271 - val_loss: 0.4807 - val_accuracy: 0.7809\n",
      "Epoch 18/30\n",
      "1152000/1152000 [==============================] - 217s 188us/step - loss: 0.3791 - accuracy: 0.8276 - val_loss: 0.4809 - val_accuracy: 0.7807\n",
      "Epoch 19/30\n",
      "1152000/1152000 [==============================] - 219s 190us/step - loss: 0.3795 - accuracy: 0.8275 - val_loss: 0.4810 - val_accuracy: 0.7809\n",
      "Epoch 20/30\n",
      "1152000/1152000 [==============================] - 221s 192us/step - loss: 0.3792 - accuracy: 0.8272 - val_loss: 0.4810 - val_accuracy: 0.7808\n",
      "Epoch 21/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3790 - accuracy: 0.8273 - val_loss: 0.4811 - val_accuracy: 0.7809\n",
      "Epoch 22/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3791 - accuracy: 0.8272 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 23/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3792 - accuracy: 0.8273 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 24/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3793 - accuracy: 0.8274 - val_loss: 0.4811 - val_accuracy: 0.7809\n",
      "Epoch 25/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3790 - accuracy: 0.8270 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 26/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3790 - accuracy: 0.8275 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 27/30\n",
      "1152000/1152000 [==============================] - 218s 189us/step - loss: 0.3792 - accuracy: 0.8274 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 28/30\n",
      "1152000/1152000 [==============================] - 218s 189us/step - loss: 0.3792 - accuracy: 0.8273 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 29/30\n",
      "1152000/1152000 [==============================] - 217s 189us/step - loss: 0.3792 - accuracy: 0.8273 - val_loss: 0.4812 - val_accuracy: 0.7809\n",
      "Epoch 30/30\n",
      "1152000/1152000 [==============================] - 218s 189us/step - loss: 0.3793 - accuracy: 0.8273 - val_loss: 0.4812 - val_accuracy: 0.7809\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    callbacks = [ \n",
    "        ReduceLROnPlateau(monitor = 'val_loss', patience = 5),\n",
    "        EarlyStopping(monitor = 'val_acc', patience = 5)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size = 1024,\n",
    "                        epochs = 30,\n",
    "                        validation_split = 0.1,\n",
    "                        verbose = 1,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    np.save(\"{}_history.npy\".format(model.name), history.history)\n",
    "    model.save(\"{}.model\".format(model.name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
