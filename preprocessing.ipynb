{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import logging\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początku zdefiniujmy sobie kilka zmiennych globalnych takich jak:\n",
    "- DATASET_PATH - ścieżkę do pliku z tweetami\n",
    "- W2V_MODEL_PATH - gdzie ma zostać zapisany model w2v\n",
    "\n",
    "- DATASET_COLUMNS - nazwy kolumn\n",
    "- DATASET_ENCODING - typ kodowaniu wykorzystany w naszym datasecie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PREPROCESSED_TEST_PATH' from 'const' (/Users/lukasz/studies/psi-project/const.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-259fb689e16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconst\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2V_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREPROCESSED_TEST_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREPROCESSED_TRAIN_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDATASET_COLUMNS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDATASET_ENCODING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PREPROCESSED_TEST_PATH' from 'const' (/Users/lukasz/studies/psi-project/const.py)"
     ]
    }
   ],
   "source": [
    "from const import DATASET_PATH, W2V_MODEL_PATH, PREPROCESSED_TEST_PATH, PREPROCESSED_TRAIN_PATH\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy teraz wczytać nasz dataset. Jako, że tweety znajdują się w pliku `csv` możemy do tego użyć wbudowanej funkcji z bilbioteki `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.abspath(DATASET_PATH), encoding = DATASET_ENCODING , names = DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Łatwo możemy sprawdzić z ilą danymi mamy tak naprawdę doczynienia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widmimy, że nasz zbiór danych składa się z 1600000 wierszy po 6 kolumn.\n",
    "\n",
    "Wyświetlmy sobie teraz pierwsze 10 wierszy naszego setu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6       0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7       0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8       0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9       0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5         joy_wolf                      @Kwesidei not the whole crew   \n",
       "6          mybirch                                        Need a hug   \n",
       "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8  2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9          mimismo                          @twittera que me muera ?   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Od razu widzimy, że niektóre z kolumn nam się nie przydadzą w dalszej analizie. Więc możemy spokojnie je usnąć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ids\", \"date\", \"flag\", \"user\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zostawiliśmy tylko dwie kolumny: `target` oraz `test`. Pierwsza z nich odpowiada emocją jakie niesie za sobą dany tweet. `0` oznacza negatywną wiadomość natomiast `4` odpowiada wiadomości pozytywnej. Teoreytcznie wartość `2` oznaczała by widomość neutralną. Jednak jak łatwo sprawdzić taka wartość nie występuje w tym zbiorze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Czyszczenie treści tweetów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy oczyścić treść posów z:\n",
    "- linków \n",
    "- nazw użytkowników\n",
    "- znaków specjalnych\n",
    "- hashtagów\n",
    "\n",
    "W tym celu posłużymy się wyrażeniami regularnymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_regex():\n",
    "    users = \"@\\S+\" # usuwa dowolne, niebiałe znaki po @ \n",
    "    links = \"((www\\.[^\\s]+)|(https?://[^\\s]+))\" # usuwa linki\n",
    "    not_alpha_numeric = \"[^A-Za-z0-9]\"\n",
    "    hashtags = \"#\\S+\" # usuwa dowolne, niebiałe znaki po #\n",
    "    return \"|\".join([users, links, not_alpha_numeric, hashtags])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@\\S+|((www\\.[^\\s]+)|(https?://[^\\s]+))|[^A-Za-z0-9]|#\\S+\n"
     ]
    }
   ],
   "source": [
    "clean_regex = get_clean_regex()\n",
    "print(clean_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: re.sub(clean_regex, ' ', str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awww  that s a bummer   you shoulda got david ...\n",
       "1    is upset that he can t update his facebook by ...\n",
       "2    i dived many times for the ball  managed to sa...\n",
       "3       my whole body feels itchy and like its on fire\n",
       "4    no  it s not behaving at all  i m mad  why am ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awww  that s a bummer   you shoulda got david carr of third day to do it   d'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Całościowo wygląda dobrze, oprócz tego, że w tekscie teraz może występować wiele białych znaków obok siebie.\n",
    "\n",
    "Dlatego, też musimy jeszcze wykonać jedną transformację na naszym zbiorze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: re.sub(\"\\s+\", ' ', str(x)).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awww that s a bummer you shoulda got david car...\n",
       "1    is upset that he can t update his facebook by ...\n",
       "2    i dived many times for the ball managed to sav...\n",
       "3       my whole body feels itchy and like its on fire\n",
       "4    no it s not behaving at all i m mad why am i h...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awww that s a bummer you shoulda got david carr of third day to do it d'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto jeszcze usunąc tak zwane **stop words** czyli słowa, których używamy ze względu na zasady gramatyczne i zwykle nie dodają znaczenia. Na przykład, są nimi: \"the\", \"a\", \"an\", \"in. \n",
    "\n",
    "Moglibyśmy sami stworzyć słownik takich zwrotów. Jednak nie jest to wymagane, poniważ możemy skorzystać z gotowego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lukasz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text, stop_words):\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df.text = df.text.apply(lambda x: remove_stop_words(str(x), stop_words).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         awww bummer shoulda got david carr third day\n",
       "1    upset update facebook texting might cry result...\n",
       "2    dived many times ball managed save 50 rest go ...\n",
       "3                     whole body feels itchy like fire\n",
       "4                                     behaving mad see\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awww bummer shoulda got david carr third day'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5).text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy teraz zająć się labelami. Tu sprawda będzie prostsza. Musimy jednynie zamienić `4` na `1`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target = df.target.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          target                                               text\n",
       "0             0       awww bummer shoulda got david carr third day\n",
       "1             0  upset update facebook texting might cry result...\n",
       "2             0  dived many times ball managed save 50 rest go ...\n",
       "3             0                   whole body feels itchy like fire\n",
       "4             0                                   behaving mad see\n",
       "...         ...                                                ...\n",
       "1599995       1                      woke school best feeling ever\n",
       "1599996       1           thewdb com cool hear old walt interviews\n",
       "1599997       1                    ready mojo makeover ask details\n",
       "1599998       1  happy 38th birthday boo alll time tupac amaru ...\n",
       "1599999       1                               happy charitytuesday\n",
       "\n",
       "[1600000 rows x 2 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charakterystyka danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonaliśmy już wstępnej obróbki danych. Jednak nie wiemy jeszcze jak wygląda rozkład labeli w naszym datasecie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12dff0cd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.target.value_counts().sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Już wiemy, że rozkład mamy tyle samo wiadomości pozytywnych co tych negatywnych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy jednocześnie policzyć jakie słowa występują najczęściej (oczywiście po wstępnym czyczeniu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_freq(document):\n",
    "    count = defaultdict(int)\n",
    "    for sentence in document:\n",
    "        for s in sentence:\n",
    "            count[s] += 1\n",
    "    return count\n",
    "count_word_freq = count_word_freq(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count\n",
      "good   73143\n",
      "day    69619\n",
      "get    65710\n",
      "like   62917\n",
      "go     59220\n",
      "quot   57523\n",
      "today  54538\n",
      "work   51806\n",
      "love   51690\n",
      "going  51557\n"
     ]
    }
   ],
   "source": [
    "word_freq_count_df = pd.DataFrame.from_dict(count_word_freq, orient='index', columns=[\"count\"])\n",
    "best_word_freq = word_freq_count_df.sort_values(by=\"count\", ascending=False)[:10]\n",
    "print(best_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189c612d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_word_freq.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podział na train i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podział danych\n",
      "  > Train:  1280000\n",
      "  > Test:  320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "print(\"Podział danych\")\n",
    "print(\"  > Train: \", len(df_train))\n",
    "print(\"  > Test: \", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "Następnym krokiem, który musismy wykonać jest zamiana słów na wektory. W tym celu posłużym się model zaimplementowanym w biliotece `gensim`. Model ten wykorzystuje prostą sieć neuronową.\n",
    "\n",
    "Aby nasze dane były kompatybilne z tym algorytmem musimy zamienić je na listę list (każde znadnie jest zamienione na osobną listę)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu monitorowania postępów dodamy loggera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy teraz model podając kilka parametrów:\n",
    "- __min_count__ - ignoruje słowa o mniejszej liczebności niż zadana\n",
    "- __size__ - rozmar wyjściowych wektorów\n",
    "- __window__ - maksymalny dystans pomiędzy słowami\n",
    "- __alpha__ - learning rate\n",
    "- __min_aplha__ - minimalna wartość learning ratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(min_count = 10,\n",
    "                                            window = 7,\n",
    "                                            size = 300,\n",
    "                                            alpha = 0.03, \n",
    "                                            min_alpha = 0.0007, \n",
    "                                            workers = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:50:07,193 : INFO : collecting all words and their counts\n",
      "2020-06-05 13:50:07,194 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-05 13:50:07,211 : INFO : PROGRESS: at sentence #10000, processed 71630 words, keeping 13450 word types\n",
      "2020-06-05 13:50:07,229 : INFO : PROGRESS: at sentence #20000, processed 143025 words, keeping 20651 word types\n",
      "2020-06-05 13:50:07,248 : INFO : PROGRESS: at sentence #30000, processed 214649 words, keeping 26205 word types\n",
      "2020-06-05 13:50:07,266 : INFO : PROGRESS: at sentence #40000, processed 286003 words, keeping 31012 word types\n",
      "2020-06-05 13:50:07,283 : INFO : PROGRESS: at sentence #50000, processed 357234 words, keeping 35411 word types\n",
      "2020-06-05 13:50:07,299 : INFO : PROGRESS: at sentence #60000, processed 429041 words, keeping 39391 word types\n",
      "2020-06-05 13:50:07,316 : INFO : PROGRESS: at sentence #70000, processed 500926 words, keeping 43090 word types\n",
      "2020-06-05 13:50:07,335 : INFO : PROGRESS: at sentence #80000, processed 572633 words, keeping 46792 word types\n",
      "2020-06-05 13:50:07,352 : INFO : PROGRESS: at sentence #90000, processed 643707 words, keeping 50149 word types\n",
      "2020-06-05 13:50:07,369 : INFO : PROGRESS: at sentence #100000, processed 715309 words, keeping 53484 word types\n",
      "2020-06-05 13:50:07,385 : INFO : PROGRESS: at sentence #110000, processed 785798 words, keeping 56537 word types\n",
      "2020-06-05 13:50:07,402 : INFO : PROGRESS: at sentence #120000, processed 856736 words, keeping 59477 word types\n",
      "2020-06-05 13:50:07,419 : INFO : PROGRESS: at sentence #130000, processed 928211 words, keeping 62379 word types\n",
      "2020-06-05 13:50:07,435 : INFO : PROGRESS: at sentence #140000, processed 999899 words, keeping 65166 word types\n",
      "2020-06-05 13:50:07,452 : INFO : PROGRESS: at sentence #150000, processed 1071537 words, keeping 67872 word types\n",
      "2020-06-05 13:50:07,469 : INFO : PROGRESS: at sentence #160000, processed 1142988 words, keeping 70443 word types\n",
      "2020-06-05 13:50:07,485 : INFO : PROGRESS: at sentence #170000, processed 1214441 words, keeping 73057 word types\n",
      "2020-06-05 13:50:07,502 : INFO : PROGRESS: at sentence #180000, processed 1285822 words, keeping 75508 word types\n",
      "2020-06-05 13:50:07,519 : INFO : PROGRESS: at sentence #190000, processed 1356982 words, keeping 77916 word types\n",
      "2020-06-05 13:50:07,536 : INFO : PROGRESS: at sentence #200000, processed 1427758 words, keeping 80279 word types\n",
      "2020-06-05 13:50:07,553 : INFO : PROGRESS: at sentence #210000, processed 1498950 words, keeping 82645 word types\n",
      "2020-06-05 13:50:07,569 : INFO : PROGRESS: at sentence #220000, processed 1569913 words, keeping 84910 word types\n",
      "2020-06-05 13:50:07,586 : INFO : PROGRESS: at sentence #230000, processed 1641861 words, keeping 87198 word types\n",
      "2020-06-05 13:50:07,606 : INFO : PROGRESS: at sentence #240000, processed 1713485 words, keeping 89442 word types\n",
      "2020-06-05 13:50:07,623 : INFO : PROGRESS: at sentence #250000, processed 1783827 words, keeping 91622 word types\n",
      "2020-06-05 13:50:07,640 : INFO : PROGRESS: at sentence #260000, processed 1855605 words, keeping 93778 word types\n",
      "2020-06-05 13:50:07,657 : INFO : PROGRESS: at sentence #270000, processed 1926503 words, keeping 95851 word types\n",
      "2020-06-05 13:50:07,674 : INFO : PROGRESS: at sentence #280000, processed 1997742 words, keeping 97907 word types\n",
      "2020-06-05 13:50:07,690 : INFO : PROGRESS: at sentence #290000, processed 2068581 words, keeping 100052 word types\n",
      "2020-06-05 13:50:07,707 : INFO : PROGRESS: at sentence #300000, processed 2140222 words, keeping 102074 word types\n",
      "2020-06-05 13:50:07,724 : INFO : PROGRESS: at sentence #310000, processed 2211393 words, keeping 104101 word types\n",
      "2020-06-05 13:50:07,742 : INFO : PROGRESS: at sentence #320000, processed 2283522 words, keeping 106098 word types\n",
      "2020-06-05 13:50:07,759 : INFO : PROGRESS: at sentence #330000, processed 2354941 words, keeping 108110 word types\n",
      "2020-06-05 13:50:07,776 : INFO : PROGRESS: at sentence #340000, processed 2426381 words, keeping 110006 word types\n",
      "2020-06-05 13:50:07,793 : INFO : PROGRESS: at sentence #350000, processed 2497593 words, keeping 111902 word types\n",
      "2020-06-05 13:50:07,811 : INFO : PROGRESS: at sentence #360000, processed 2569358 words, keeping 113798 word types\n",
      "2020-06-05 13:50:07,828 : INFO : PROGRESS: at sentence #370000, processed 2640290 words, keeping 115651 word types\n",
      "2020-06-05 13:50:07,845 : INFO : PROGRESS: at sentence #380000, processed 2711675 words, keeping 117623 word types\n",
      "2020-06-05 13:50:07,863 : INFO : PROGRESS: at sentence #390000, processed 2783067 words, keeping 119464 word types\n",
      "2020-06-05 13:50:07,880 : INFO : PROGRESS: at sentence #400000, processed 2854840 words, keeping 121287 word types\n",
      "2020-06-05 13:50:07,898 : INFO : PROGRESS: at sentence #410000, processed 2926930 words, keeping 123131 word types\n",
      "2020-06-05 13:50:07,915 : INFO : PROGRESS: at sentence #420000, processed 2998123 words, keeping 124871 word types\n",
      "2020-06-05 13:50:07,933 : INFO : PROGRESS: at sentence #430000, processed 3069585 words, keeping 126660 word types\n",
      "2020-06-05 13:50:07,950 : INFO : PROGRESS: at sentence #440000, processed 3141148 words, keeping 128367 word types\n",
      "2020-06-05 13:50:07,967 : INFO : PROGRESS: at sentence #450000, processed 3213416 words, keeping 130111 word types\n",
      "2020-06-05 13:50:07,985 : INFO : PROGRESS: at sentence #460000, processed 3285588 words, keeping 131831 word types\n",
      "2020-06-05 13:50:08,003 : INFO : PROGRESS: at sentence #470000, processed 3356567 words, keeping 133511 word types\n",
      "2020-06-05 13:50:08,020 : INFO : PROGRESS: at sentence #480000, processed 3428149 words, keeping 135252 word types\n",
      "2020-06-05 13:50:08,038 : INFO : PROGRESS: at sentence #490000, processed 3498967 words, keeping 136980 word types\n",
      "2020-06-05 13:50:08,056 : INFO : PROGRESS: at sentence #500000, processed 3570493 words, keeping 138568 word types\n",
      "2020-06-05 13:50:08,073 : INFO : PROGRESS: at sentence #510000, processed 3642241 words, keeping 140196 word types\n",
      "2020-06-05 13:50:08,090 : INFO : PROGRESS: at sentence #520000, processed 3713970 words, keeping 141876 word types\n",
      "2020-06-05 13:50:08,107 : INFO : PROGRESS: at sentence #530000, processed 3785596 words, keeping 143458 word types\n",
      "2020-06-05 13:50:08,125 : INFO : PROGRESS: at sentence #540000, processed 3857578 words, keeping 145162 word types\n",
      "2020-06-05 13:50:08,143 : INFO : PROGRESS: at sentence #550000, processed 3929016 words, keeping 146779 word types\n",
      "2020-06-05 13:50:08,161 : INFO : PROGRESS: at sentence #560000, processed 4000527 words, keeping 148437 word types\n",
      "2020-06-05 13:50:08,178 : INFO : PROGRESS: at sentence #570000, processed 4070784 words, keeping 150072 word types\n",
      "2020-06-05 13:50:08,196 : INFO : PROGRESS: at sentence #580000, processed 4141439 words, keeping 151655 word types\n",
      "2020-06-05 13:50:08,213 : INFO : PROGRESS: at sentence #590000, processed 4212080 words, keeping 153284 word types\n",
      "2020-06-05 13:50:08,231 : INFO : PROGRESS: at sentence #600000, processed 4283142 words, keeping 154751 word types\n",
      "2020-06-05 13:50:08,250 : INFO : PROGRESS: at sentence #610000, processed 4354918 words, keeping 156274 word types\n",
      "2020-06-05 13:50:08,269 : INFO : PROGRESS: at sentence #620000, processed 4426621 words, keeping 157826 word types\n",
      "2020-06-05 13:50:08,288 : INFO : PROGRESS: at sentence #630000, processed 4498454 words, keeping 159368 word types\n",
      "2020-06-05 13:50:08,307 : INFO : PROGRESS: at sentence #640000, processed 4570210 words, keeping 160929 word types\n",
      "2020-06-05 13:50:08,325 : INFO : PROGRESS: at sentence #650000, processed 4641623 words, keeping 162341 word types\n",
      "2020-06-05 13:50:08,344 : INFO : PROGRESS: at sentence #660000, processed 4713495 words, keeping 163928 word types\n",
      "2020-06-05 13:50:08,361 : INFO : PROGRESS: at sentence #670000, processed 4785015 words, keeping 165390 word types\n",
      "2020-06-05 13:50:08,378 : INFO : PROGRESS: at sentence #680000, processed 4855924 words, keeping 166805 word types\n",
      "2020-06-05 13:50:08,396 : INFO : PROGRESS: at sentence #690000, processed 4927269 words, keeping 168300 word types\n",
      "2020-06-05 13:50:08,413 : INFO : PROGRESS: at sentence #700000, processed 4998395 words, keeping 169766 word types\n",
      "2020-06-05 13:50:08,430 : INFO : PROGRESS: at sentence #710000, processed 5069400 words, keeping 171140 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:50:08,449 : INFO : PROGRESS: at sentence #720000, processed 5141601 words, keeping 172573 word types\n",
      "2020-06-05 13:50:08,466 : INFO : PROGRESS: at sentence #730000, processed 5212523 words, keeping 173993 word types\n",
      "2020-06-05 13:50:08,490 : INFO : PROGRESS: at sentence #740000, processed 5283772 words, keeping 175383 word types\n",
      "2020-06-05 13:50:08,508 : INFO : PROGRESS: at sentence #750000, processed 5356209 words, keeping 176819 word types\n",
      "2020-06-05 13:50:08,526 : INFO : PROGRESS: at sentence #760000, processed 5427493 words, keeping 178206 word types\n",
      "2020-06-05 13:50:08,544 : INFO : PROGRESS: at sentence #770000, processed 5498778 words, keeping 179613 word types\n",
      "2020-06-05 13:50:08,561 : INFO : PROGRESS: at sentence #780000, processed 5569334 words, keeping 180986 word types\n",
      "2020-06-05 13:50:08,579 : INFO : PROGRESS: at sentence #790000, processed 5640375 words, keeping 182391 word types\n",
      "2020-06-05 13:50:08,597 : INFO : PROGRESS: at sentence #800000, processed 5711084 words, keeping 183722 word types\n",
      "2020-06-05 13:50:08,614 : INFO : PROGRESS: at sentence #810000, processed 5782142 words, keeping 185070 word types\n",
      "2020-06-05 13:50:08,632 : INFO : PROGRESS: at sentence #820000, processed 5853564 words, keeping 186447 word types\n",
      "2020-06-05 13:50:08,650 : INFO : PROGRESS: at sentence #830000, processed 5925376 words, keeping 187802 word types\n",
      "2020-06-05 13:50:08,667 : INFO : PROGRESS: at sentence #840000, processed 5997006 words, keeping 189228 word types\n",
      "2020-06-05 13:50:08,686 : INFO : PROGRESS: at sentence #850000, processed 6068042 words, keeping 190612 word types\n",
      "2020-06-05 13:50:08,704 : INFO : PROGRESS: at sentence #860000, processed 6139709 words, keeping 191967 word types\n",
      "2020-06-05 13:50:08,722 : INFO : PROGRESS: at sentence #870000, processed 6210742 words, keeping 193280 word types\n",
      "2020-06-05 13:50:08,740 : INFO : PROGRESS: at sentence #880000, processed 6282727 words, keeping 194619 word types\n",
      "2020-06-05 13:50:08,757 : INFO : PROGRESS: at sentence #890000, processed 6354084 words, keeping 195943 word types\n",
      "2020-06-05 13:50:08,775 : INFO : PROGRESS: at sentence #900000, processed 6425076 words, keeping 197298 word types\n",
      "2020-06-05 13:50:08,793 : INFO : PROGRESS: at sentence #910000, processed 6496378 words, keeping 198631 word types\n",
      "2020-06-05 13:50:08,811 : INFO : PROGRESS: at sentence #920000, processed 6567150 words, keeping 199964 word types\n",
      "2020-06-05 13:50:08,828 : INFO : PROGRESS: at sentence #930000, processed 6638200 words, keeping 201265 word types\n",
      "2020-06-05 13:50:08,846 : INFO : PROGRESS: at sentence #940000, processed 6709781 words, keeping 202574 word types\n",
      "2020-06-05 13:50:08,864 : INFO : PROGRESS: at sentence #950000, processed 6781581 words, keeping 203902 word types\n",
      "2020-06-05 13:50:08,882 : INFO : PROGRESS: at sentence #960000, processed 6853400 words, keeping 205224 word types\n",
      "2020-06-05 13:50:08,900 : INFO : PROGRESS: at sentence #970000, processed 6924935 words, keeping 206516 word types\n",
      "2020-06-05 13:50:08,918 : INFO : PROGRESS: at sentence #980000, processed 6995972 words, keeping 207849 word types\n",
      "2020-06-05 13:50:08,936 : INFO : PROGRESS: at sentence #990000, processed 7067323 words, keeping 209163 word types\n",
      "2020-06-05 13:50:08,955 : INFO : PROGRESS: at sentence #1000000, processed 7138900 words, keeping 210504 word types\n",
      "2020-06-05 13:50:08,973 : INFO : PROGRESS: at sentence #1010000, processed 7210911 words, keeping 211847 word types\n",
      "2020-06-05 13:50:08,990 : INFO : PROGRESS: at sentence #1020000, processed 7281735 words, keeping 213134 word types\n",
      "2020-06-05 13:50:09,008 : INFO : PROGRESS: at sentence #1030000, processed 7353582 words, keeping 214455 word types\n",
      "2020-06-05 13:50:09,026 : INFO : PROGRESS: at sentence #1040000, processed 7425129 words, keeping 215826 word types\n",
      "2020-06-05 13:50:09,043 : INFO : PROGRESS: at sentence #1050000, processed 7496728 words, keeping 217142 word types\n",
      "2020-06-05 13:50:09,061 : INFO : PROGRESS: at sentence #1060000, processed 7568287 words, keeping 218370 word types\n",
      "2020-06-05 13:50:09,078 : INFO : PROGRESS: at sentence #1070000, processed 7640523 words, keeping 219579 word types\n",
      "2020-06-05 13:50:09,096 : INFO : PROGRESS: at sentence #1080000, processed 7711538 words, keeping 220796 word types\n",
      "2020-06-05 13:50:09,113 : INFO : PROGRESS: at sentence #1090000, processed 7782533 words, keeping 222050 word types\n",
      "2020-06-05 13:50:09,131 : INFO : PROGRESS: at sentence #1100000, processed 7854282 words, keeping 223312 word types\n",
      "2020-06-05 13:50:09,147 : INFO : PROGRESS: at sentence #1110000, processed 7925720 words, keeping 224561 word types\n",
      "2020-06-05 13:50:09,164 : INFO : PROGRESS: at sentence #1120000, processed 7997428 words, keeping 225737 word types\n",
      "2020-06-05 13:50:09,182 : INFO : PROGRESS: at sentence #1130000, processed 8069209 words, keeping 226952 word types\n",
      "2020-06-05 13:50:09,199 : INFO : PROGRESS: at sentence #1140000, processed 8141129 words, keeping 228195 word types\n",
      "2020-06-05 13:50:09,216 : INFO : PROGRESS: at sentence #1150000, processed 8212421 words, keeping 229393 word types\n",
      "2020-06-05 13:50:09,233 : INFO : PROGRESS: at sentence #1160000, processed 8283675 words, keeping 230615 word types\n",
      "2020-06-05 13:50:09,250 : INFO : PROGRESS: at sentence #1170000, processed 8355216 words, keeping 231806 word types\n",
      "2020-06-05 13:50:09,267 : INFO : PROGRESS: at sentence #1180000, processed 8426400 words, keeping 232969 word types\n",
      "2020-06-05 13:50:09,284 : INFO : PROGRESS: at sentence #1190000, processed 8497756 words, keeping 234092 word types\n",
      "2020-06-05 13:50:09,302 : INFO : PROGRESS: at sentence #1200000, processed 8569302 words, keeping 235340 word types\n",
      "2020-06-05 13:50:09,319 : INFO : PROGRESS: at sentence #1210000, processed 8641446 words, keeping 236555 word types\n",
      "2020-06-05 13:50:09,337 : INFO : PROGRESS: at sentence #1220000, processed 8713016 words, keeping 237732 word types\n",
      "2020-06-05 13:50:09,354 : INFO : PROGRESS: at sentence #1230000, processed 8783705 words, keeping 238832 word types\n",
      "2020-06-05 13:50:09,371 : INFO : PROGRESS: at sentence #1240000, processed 8855308 words, keeping 239990 word types\n",
      "2020-06-05 13:50:09,388 : INFO : PROGRESS: at sentence #1250000, processed 8926402 words, keeping 241133 word types\n",
      "2020-06-05 13:50:09,406 : INFO : PROGRESS: at sentence #1260000, processed 8997793 words, keeping 242288 word types\n",
      "2020-06-05 13:50:09,423 : INFO : PROGRESS: at sentence #1270000, processed 9069085 words, keeping 243469 word types\n",
      "2020-06-05 13:50:09,439 : INFO : collected 244666 word types from a corpus of 9140124 raw words and 1280000 sentences\n",
      "2020-06-05 13:50:09,440 : INFO : Loading a fresh vocabulary\n",
      "2020-06-05 13:50:09,886 : INFO : effective_min_count=10 retains 30067 unique words (12% of original 244666, drops 214599)\n",
      "2020-06-05 13:50:09,886 : INFO : effective_min_count=10 leaves 8752952 word corpus (95% of original 9140124, drops 387172)\n",
      "2020-06-05 13:50:09,955 : INFO : deleting the raw counts dictionary of 244666 items\n",
      "2020-06-05 13:50:09,960 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-06-05 13:50:09,961 : INFO : downsampling leaves estimated 8192767 word corpus (93.6% of prior 8752952)\n",
      "2020-06-05 13:50:10,036 : INFO : estimated required memory for 30067 words and 300 dimensions: 87194300 bytes\n",
      "2020-06-05 13:50:10,037 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy teraz wytrenować nasz model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:51:41,288 : INFO : training model with 7 workers on 30067 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2020-06-05 13:51:42,302 : INFO : EPOCH 1 - PROGRESS: at 19.48% examples, 1591574 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:51:43,305 : INFO : EPOCH 1 - PROGRESS: at 39.47% examples, 1613146 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:51:44,310 : INFO : EPOCH 1 - PROGRESS: at 60.04% examples, 1634635 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:51:45,310 : INFO : EPOCH 1 - PROGRESS: at 80.07% examples, 1635601 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:51:46,295 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:51:46,300 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:51:46,301 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:51:46,306 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:51:46,310 : INFO : EPOCH 1 - PROGRESS: at 99.78% examples, 1631668 words/s, in_qsize 2, out_qsize 1\n",
      "2020-06-05 13:51:46,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:51:46,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:51:46,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:51:46,319 : INFO : EPOCH - 1 : training on 9140124 raw words (8192433 effective words) took 5.0s, 1632553 effective words/s\n",
      "2020-06-05 13:51:47,340 : INFO : EPOCH 2 - PROGRESS: at 20.14% examples, 1631649 words/s, in_qsize 13, out_qsize 1\n",
      "2020-06-05 13:51:48,351 : INFO : EPOCH 2 - PROGRESS: at 41.22% examples, 1671137 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:51:49,354 : INFO : EPOCH 2 - PROGRESS: at 61.14% examples, 1655859 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:51:50,355 : INFO : EPOCH 2 - PROGRESS: at 81.27% examples, 1653903 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:51:51,212 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:51:51,214 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:51:51,217 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:51:51,221 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:51:51,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:51:51,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:51:51,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:51:51,232 : INFO : EPOCH - 2 : training on 9140124 raw words (8192984 effective words) took 4.9s, 1671166 effective words/s\n",
      "2020-06-05 13:51:52,244 : INFO : EPOCH 3 - PROGRESS: at 19.70% examples, 1606491 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:51:53,246 : INFO : EPOCH 3 - PROGRESS: at 40.02% examples, 1635033 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:51:54,252 : INFO : EPOCH 3 - PROGRESS: at 61.03% examples, 1660042 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:51:55,257 : INFO : EPOCH 3 - PROGRESS: at 81.92% examples, 1670735 words/s, in_qsize 13, out_qsize 1\n",
      "2020-06-05 13:51:56,084 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:51:56,086 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:51:56,089 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:51:56,093 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:51:56,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:51:56,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:51:56,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:51:56,105 : INFO : EPOCH - 3 : training on 9140124 raw words (8192332 effective words) took 4.9s, 1684312 effective words/s\n",
      "2020-06-05 13:51:57,123 : INFO : EPOCH 4 - PROGRESS: at 18.92% examples, 1539638 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:51:58,125 : INFO : EPOCH 4 - PROGRESS: at 39.04% examples, 1592065 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:51:59,135 : INFO : EPOCH 4 - PROGRESS: at 59.93% examples, 1626231 words/s, in_qsize 14, out_qsize 1\n",
      "2020-06-05 13:52:00,136 : INFO : EPOCH 4 - PROGRESS: at 79.08% examples, 1611343 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:01,152 : INFO : EPOCH 4 - PROGRESS: at 96.34% examples, 1567607 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:01,328 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:01,332 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:01,334 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:01,339 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:01,340 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:01,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:01,354 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:01,354 : INFO : EPOCH - 4 : training on 9140124 raw words (8192657 effective words) took 5.2s, 1564022 effective words/s\n",
      "2020-06-05 13:52:02,374 : INFO : EPOCH 5 - PROGRESS: at 17.29% examples, 1404923 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:03,382 : INFO : EPOCH 5 - PROGRESS: at 35.00% examples, 1422804 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:04,387 : INFO : EPOCH 5 - PROGRESS: at 51.61% examples, 1400032 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:05,391 : INFO : EPOCH 5 - PROGRESS: at 70.12% examples, 1427243 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:06,399 : INFO : EPOCH 5 - PROGRESS: at 87.06% examples, 1417304 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:52:07,119 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:07,123 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:07,125 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:07,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:07,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:07,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:07,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:07,144 : INFO : EPOCH - 5 : training on 9140124 raw words (8193303 effective words) took 5.8s, 1418094 effective words/s\n",
      "2020-06-05 13:52:08,160 : INFO : EPOCH 6 - PROGRESS: at 18.92% examples, 1544999 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:09,162 : INFO : EPOCH 6 - PROGRESS: at 36.30% examples, 1483423 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:10,173 : INFO : EPOCH 6 - PROGRESS: at 53.70% examples, 1458539 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:11,184 : INFO : EPOCH 6 - PROGRESS: at 71.22% examples, 1448459 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:12,190 : INFO : EPOCH 6 - PROGRESS: at 91.10% examples, 1482782 words/s, in_qsize 13, out_qsize 1\n",
      "2020-06-05 13:52:12,577 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:12,581 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:12,582 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:12,587 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:12,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:12,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:12,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:12,598 : INFO : EPOCH - 6 : training on 9140124 raw words (8193753 effective words) took 5.4s, 1505910 effective words/s\n",
      "2020-06-05 13:52:13,613 : INFO : EPOCH 7 - PROGRESS: at 19.26% examples, 1570447 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:14,617 : INFO : EPOCH 7 - PROGRESS: at 37.06% examples, 1512219 words/s, in_qsize 12, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:52:15,627 : INFO : EPOCH 7 - PROGRESS: at 55.67% examples, 1511012 words/s, in_qsize 14, out_qsize 1\n",
      "2020-06-05 13:52:16,631 : INFO : EPOCH 7 - PROGRESS: at 72.87% examples, 1483576 words/s, in_qsize 13, out_qsize 2\n",
      "2020-06-05 13:52:17,632 : INFO : EPOCH 7 - PROGRESS: at 91.86% examples, 1498396 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:18,071 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:18,075 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:18,076 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:18,081 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:18,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:18,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:18,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:18,095 : INFO : EPOCH - 7 : training on 9140124 raw words (8192217 effective words) took 5.5s, 1493335 effective words/s\n",
      "2020-06-05 13:52:19,112 : INFO : EPOCH 8 - PROGRESS: at 17.18% examples, 1398395 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:20,115 : INFO : EPOCH 8 - PROGRESS: at 34.13% examples, 1391348 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:21,124 : INFO : EPOCH 8 - PROGRESS: at 52.59% examples, 1427802 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:52:22,125 : INFO : EPOCH 8 - PROGRESS: at 70.89% examples, 1444644 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:23,127 : INFO : EPOCH 8 - PROGRESS: at 89.56% examples, 1461368 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:23,614 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:23,619 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:23,621 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:23,625 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:23,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:23,632 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:23,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:23,637 : INFO : EPOCH - 8 : training on 9140124 raw words (8192468 effective words) took 5.5s, 1481276 effective words/s\n",
      "2020-06-05 13:52:24,655 : INFO : EPOCH 9 - PROGRESS: at 20.13% examples, 1635800 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:25,673 : INFO : EPOCH 9 - PROGRESS: at 39.15% examples, 1583135 words/s, in_qsize 14, out_qsize 1\n",
      "2020-06-05 13:52:26,674 : INFO : EPOCH 9 - PROGRESS: at 57.64% examples, 1560124 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:27,683 : INFO : EPOCH 9 - PROGRESS: at 76.90% examples, 1560971 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:28,685 : INFO : EPOCH 9 - PROGRESS: at 96.89% examples, 1575940 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:28,807 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:28,811 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:28,813 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:28,818 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:28,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:28,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:28,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:28,831 : INFO : EPOCH - 9 : training on 9140124 raw words (8193232 effective words) took 5.2s, 1580550 effective words/s\n",
      "2020-06-05 13:52:29,847 : INFO : EPOCH 10 - PROGRESS: at 18.05% examples, 1470392 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:30,857 : INFO : EPOCH 10 - PROGRESS: at 37.50% examples, 1525632 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:31,859 : INFO : EPOCH 10 - PROGRESS: at 57.31% examples, 1556359 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:52:32,860 : INFO : EPOCH 10 - PROGRESS: at 77.01% examples, 1570041 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:33,866 : INFO : EPOCH 10 - PROGRESS: at 96.77% examples, 1578310 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:33,996 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:34,003 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:34,004 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:34,009 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:34,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:34,019 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:34,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:34,020 : INFO : EPOCH - 10 : training on 9140124 raw words (8193226 effective words) took 5.2s, 1582241 effective words/s\n",
      "2020-06-05 13:52:35,049 : INFO : EPOCH 11 - PROGRESS: at 19.59% examples, 1589218 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:36,059 : INFO : EPOCH 11 - PROGRESS: at 37.72% examples, 1530806 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:37,063 : INFO : EPOCH 11 - PROGRESS: at 56.32% examples, 1526364 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:38,074 : INFO : EPOCH 11 - PROGRESS: at 73.95% examples, 1501612 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:39,082 : INFO : EPOCH 11 - PROGRESS: at 90.65% examples, 1473134 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:39,611 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:39,614 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:39,616 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:39,622 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:39,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:39,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:39,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:39,636 : INFO : EPOCH - 11 : training on 9140124 raw words (8193097 effective words) took 5.6s, 1463997 effective words/s\n",
      "2020-06-05 13:52:40,662 : INFO : EPOCH 12 - PROGRESS: at 15.53% examples, 1253868 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:52:41,675 : INFO : EPOCH 12 - PROGRESS: at 32.27% examples, 1303888 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:42,683 : INFO : EPOCH 12 - PROGRESS: at 49.32% examples, 1331142 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:43,694 : INFO : EPOCH 12 - PROGRESS: at 66.18% examples, 1339885 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:44,698 : INFO : EPOCH 12 - PROGRESS: at 84.65% examples, 1373189 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:45,460 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:45,464 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:45,465 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:45,470 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:45,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:45,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:45,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:45,484 : INFO : EPOCH - 12 : training on 9140124 raw words (8192524 effective words) took 5.8s, 1403806 effective words/s\n",
      "2020-06-05 13:52:46,497 : INFO : EPOCH 13 - PROGRESS: at 18.70% examples, 1527195 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:47,505 : INFO : EPOCH 13 - PROGRESS: at 38.39% examples, 1563731 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:48,516 : INFO : EPOCH 13 - PROGRESS: at 57.96% examples, 1571112 words/s, in_qsize 13, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:52:49,517 : INFO : EPOCH 13 - PROGRESS: at 77.34% examples, 1574212 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:50,520 : INFO : EPOCH 13 - PROGRESS: at 96.56% examples, 1573923 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:50,663 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:50,669 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:50,671 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:50,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:50,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:50,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:50,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:50,688 : INFO : EPOCH - 13 : training on 9140124 raw words (8193044 effective words) took 5.2s, 1577316 effective words/s\n",
      "2020-06-05 13:52:51,701 : INFO : EPOCH 14 - PROGRESS: at 19.03% examples, 1555852 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:52,715 : INFO : EPOCH 14 - PROGRESS: at 38.71% examples, 1573623 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:53,718 : INFO : EPOCH 14 - PROGRESS: at 58.28% examples, 1582272 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:52:54,725 : INFO : EPOCH 14 - PROGRESS: at 78.00% examples, 1586993 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:52:55,730 : INFO : EPOCH 14 - PROGRESS: at 95.68% examples, 1558350 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:55,927 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:52:55,931 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:52:55,940 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:52:55,942 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:52:55,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:52:55,951 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:52:55,952 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:52:55,953 : INFO : EPOCH - 14 : training on 9140124 raw words (8194335 effective words) took 5.3s, 1559609 effective words/s\n",
      "2020-06-05 13:52:56,971 : INFO : EPOCH 15 - PROGRESS: at 17.40% examples, 1423928 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:57,976 : INFO : EPOCH 15 - PROGRESS: at 34.78% examples, 1420845 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:52:58,986 : INFO : EPOCH 15 - PROGRESS: at 52.27% examples, 1420362 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:52:59,990 : INFO : EPOCH 15 - PROGRESS: at 69.68% examples, 1420002 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:01,001 : INFO : EPOCH 15 - PROGRESS: at 87.60% examples, 1426675 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:01,619 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:01,626 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:01,627 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:01,632 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:01,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:01,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:01,643 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:01,643 : INFO : EPOCH - 15 : training on 9140124 raw words (8192124 effective words) took 5.7s, 1444189 effective words/s\n",
      "2020-06-05 13:53:02,656 : INFO : EPOCH 16 - PROGRESS: at 15.64% examples, 1274922 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:03,657 : INFO : EPOCH 16 - PROGRESS: at 31.08% examples, 1268351 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:04,660 : INFO : EPOCH 16 - PROGRESS: at 48.79% examples, 1328172 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:05,662 : INFO : EPOCH 16 - PROGRESS: at 66.18% examples, 1351854 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:06,663 : INFO : EPOCH 16 - PROGRESS: at 82.91% examples, 1355243 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:07,630 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:07,636 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:07,637 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:07,642 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:07,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:07,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:07,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:07,654 : INFO : EPOCH - 16 : training on 9140124 raw words (8194266 effective words) took 6.0s, 1365073 effective words/s\n",
      "2020-06-05 13:53:08,671 : INFO : EPOCH 17 - PROGRESS: at 17.40% examples, 1415201 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:09,677 : INFO : EPOCH 17 - PROGRESS: at 35.00% examples, 1424750 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:10,679 : INFO : EPOCH 17 - PROGRESS: at 52.60% examples, 1429583 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:11,685 : INFO : EPOCH 17 - PROGRESS: at 69.68% examples, 1419780 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:12,697 : INFO : EPOCH 17 - PROGRESS: at 86.62% examples, 1410114 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:13,421 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:13,428 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:13,430 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:13,435 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:13,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:13,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:13,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:13,447 : INFO : EPOCH - 17 : training on 9140124 raw words (8193252 effective words) took 5.8s, 1416954 effective words/s\n",
      "2020-06-05 13:53:14,474 : INFO : EPOCH 18 - PROGRESS: at 17.07% examples, 1378023 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:15,483 : INFO : EPOCH 18 - PROGRESS: at 34.24% examples, 1386515 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:16,485 : INFO : EPOCH 18 - PROGRESS: at 51.40% examples, 1391900 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:17,491 : INFO : EPOCH 18 - PROGRESS: at 68.80% examples, 1398278 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:18,494 : INFO : EPOCH 18 - PROGRESS: at 87.38% examples, 1422180 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:19,294 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:19,300 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:19,301 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:19,306 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:19,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:19,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:19,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:19,317 : INFO : EPOCH - 18 : training on 9140124 raw words (8194366 effective words) took 5.9s, 1398888 effective words/s\n",
      "2020-06-05 13:53:20,337 : INFO : EPOCH 19 - PROGRESS: at 16.85% examples, 1365802 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:21,342 : INFO : EPOCH 19 - PROGRESS: at 33.48% examples, 1360534 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:22,349 : INFO : EPOCH 19 - PROGRESS: at 49.44% examples, 1339792 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:23,362 : INFO : EPOCH 19 - PROGRESS: at 65.09% examples, 1321215 words/s, in_qsize 13, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:53:24,368 : INFO : EPOCH 19 - PROGRESS: at 81.16% examples, 1318992 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:25,368 : INFO : EPOCH 19 - PROGRESS: at 97.21% examples, 1318632 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:25,483 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:25,489 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:25,490 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:25,495 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:25,499 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:25,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:25,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:25,506 : INFO : EPOCH - 19 : training on 9140124 raw words (8192496 effective words) took 6.2s, 1326033 effective words/s\n",
      "2020-06-05 13:53:26,521 : INFO : EPOCH 20 - PROGRESS: at 16.85% examples, 1373546 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:27,533 : INFO : EPOCH 20 - PROGRESS: at 35.32% examples, 1435351 words/s, in_qsize 13, out_qsize 1\n",
      "2020-06-05 13:53:28,533 : INFO : EPOCH 20 - PROGRESS: at 52.05% examples, 1413812 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:29,538 : INFO : EPOCH 20 - PROGRESS: at 68.80% examples, 1401504 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:30,540 : INFO : EPOCH 20 - PROGRESS: at 83.99% examples, 1370048 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:31,439 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:31,441 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:31,444 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:31,449 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:31,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:31,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:31,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:31,463 : INFO : EPOCH - 20 : training on 9140124 raw words (8193127 effective words) took 5.9s, 1377940 effective words/s\n",
      "2020-06-05 13:53:32,480 : INFO : EPOCH 21 - PROGRESS: at 17.72% examples, 1442003 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:33,481 : INFO : EPOCH 21 - PROGRESS: at 34.34% examples, 1401884 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:34,481 : INFO : EPOCH 21 - PROGRESS: at 51.50% examples, 1403255 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:35,495 : INFO : EPOCH 21 - PROGRESS: at 69.35% examples, 1412655 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:36,501 : INFO : EPOCH 21 - PROGRESS: at 86.95% examples, 1416897 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:37,211 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:37,213 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:37,220 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:37,221 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:37,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:37,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:37,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:37,235 : INFO : EPOCH - 21 : training on 9140124 raw words (8192324 effective words) took 5.8s, 1422030 effective words/s\n",
      "2020-06-05 13:53:38,265 : INFO : EPOCH 22 - PROGRESS: at 15.97% examples, 1284891 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:39,273 : INFO : EPOCH 22 - PROGRESS: at 33.15% examples, 1339478 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:40,286 : INFO : EPOCH 22 - PROGRESS: at 51.07% examples, 1376676 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:41,293 : INFO : EPOCH 22 - PROGRESS: at 68.91% examples, 1395019 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:53:42,297 : INFO : EPOCH 22 - PROGRESS: at 86.29% examples, 1399640 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:43,040 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:43,045 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:43,047 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:43,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:43,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:43,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:43,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:43,063 : INFO : EPOCH - 22 : training on 9140124 raw words (8192922 effective words) took 5.8s, 1408652 effective words/s\n",
      "2020-06-05 13:53:44,081 : INFO : EPOCH 23 - PROGRESS: at 17.62% examples, 1432732 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:45,082 : INFO : EPOCH 23 - PROGRESS: at 34.89% examples, 1423260 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:46,085 : INFO : EPOCH 23 - PROGRESS: at 51.94% examples, 1413427 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:47,097 : INFO : EPOCH 23 - PROGRESS: at 69.46% examples, 1414419 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:48,103 : INFO : EPOCH 23 - PROGRESS: at 87.16% examples, 1419680 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:48,821 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:48,823 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:48,826 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:48,830 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:48,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:48,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:48,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:48,846 : INFO : EPOCH - 23 : training on 9140124 raw words (8192390 effective words) took 5.8s, 1419380 effective words/s\n",
      "2020-06-05 13:53:49,866 : INFO : EPOCH 24 - PROGRESS: at 15.97% examples, 1296133 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:50,876 : INFO : EPOCH 24 - PROGRESS: at 31.73% examples, 1287169 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:51,888 : INFO : EPOCH 24 - PROGRESS: at 47.91% examples, 1294856 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:52,899 : INFO : EPOCH 24 - PROGRESS: at 65.52% examples, 1327972 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:53,903 : INFO : EPOCH 24 - PROGRESS: at 82.14% examples, 1333489 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:53:54,870 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:53:54,874 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:53:54,882 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:53:54,883 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:53:54,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:53:54,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:53:54,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:53:54,894 : INFO : EPOCH - 24 : training on 9140124 raw words (8193197 effective words) took 6.0s, 1357292 effective words/s\n",
      "2020-06-05 13:53:55,905 : INFO : EPOCH 25 - PROGRESS: at 16.96% examples, 1386802 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:56,910 : INFO : EPOCH 25 - PROGRESS: at 34.35% examples, 1402113 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:53:57,915 : INFO : EPOCH 25 - PROGRESS: at 50.96% examples, 1386402 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:53:58,923 : INFO : EPOCH 25 - PROGRESS: at 68.26% examples, 1391102 words/s, in_qsize 13, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 13:53:59,933 : INFO : EPOCH 25 - PROGRESS: at 86.08% examples, 1402062 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:00,635 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:00,639 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:00,646 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:00,647 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:00,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:00,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:00,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:00,659 : INFO : EPOCH - 25 : training on 9140124 raw words (8192780 effective words) took 5.8s, 1423570 effective words/s\n",
      "2020-06-05 13:54:01,672 : INFO : EPOCH 26 - PROGRESS: at 19.15% examples, 1563680 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:02,687 : INFO : EPOCH 26 - PROGRESS: at 38.06% examples, 1545667 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:03,695 : INFO : EPOCH 26 - PROGRESS: at 56.32% examples, 1525269 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:04,700 : INFO : EPOCH 26 - PROGRESS: at 73.74% examples, 1498274 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:05,704 : INFO : EPOCH 26 - PROGRESS: at 91.75% examples, 1493274 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:06,120 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:06,125 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:06,126 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:06,132 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:06,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:06,138 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:06,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:06,143 : INFO : EPOCH - 26 : training on 9140124 raw words (8193450 effective words) took 5.5s, 1496995 effective words/s\n",
      "2020-06-05 13:54:07,160 : INFO : EPOCH 27 - PROGRESS: at 16.85% examples, 1371713 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:08,160 : INFO : EPOCH 27 - PROGRESS: at 34.35% examples, 1402638 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:09,166 : INFO : EPOCH 27 - PROGRESS: at 53.15% examples, 1445569 words/s, in_qsize 13, out_qsize 1\n",
      "2020-06-05 13:54:10,172 : INFO : EPOCH 27 - PROGRESS: at 72.86% examples, 1484966 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:11,175 : INFO : EPOCH 27 - PROGRESS: at 92.52% examples, 1509703 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:11,513 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:11,517 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:11,525 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:11,526 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:11,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:11,534 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:11,535 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:11,536 : INFO : EPOCH - 27 : training on 9140124 raw words (8192054 effective words) took 5.4s, 1522155 effective words/s\n",
      "2020-06-05 13:54:12,555 : INFO : EPOCH 28 - PROGRESS: at 19.26% examples, 1572090 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:13,559 : INFO : EPOCH 28 - PROGRESS: at 38.93% examples, 1589131 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:14,561 : INFO : EPOCH 28 - PROGRESS: at 55.45% examples, 1509635 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:15,566 : INFO : EPOCH 28 - PROGRESS: at 71.98% examples, 1468709 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:16,571 : INFO : EPOCH 28 - PROGRESS: at 89.23% examples, 1456802 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:17,149 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:17,153 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:17,162 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:17,162 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:17,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:17,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:17,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:17,175 : INFO : EPOCH - 28 : training on 9140124 raw words (8192664 effective words) took 5.6s, 1457105 effective words/s\n",
      "2020-06-05 13:54:18,195 : INFO : EPOCH 29 - PROGRESS: at 16.96% examples, 1386250 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:54:19,198 : INFO : EPOCH 29 - PROGRESS: at 33.80% examples, 1381066 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:20,213 : INFO : EPOCH 29 - PROGRESS: at 52.27% examples, 1418564 words/s, in_qsize 11, out_qsize 2\n",
      "2020-06-05 13:54:21,217 : INFO : EPOCH 29 - PROGRESS: at 70.99% examples, 1445431 words/s, in_qsize 14, out_qsize 0\n",
      "2020-06-05 13:54:22,221 : INFO : EPOCH 29 - PROGRESS: at 87.93% examples, 1432777 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:22,897 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:22,902 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:22,904 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:22,910 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:22,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:22,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:22,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:22,921 : INFO : EPOCH - 29 : training on 9140124 raw words (8193211 effective words) took 5.7s, 1430407 effective words/s\n",
      "2020-06-05 13:54:23,931 : INFO : EPOCH 30 - PROGRESS: at 17.18% examples, 1404396 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:24,943 : INFO : EPOCH 30 - PROGRESS: at 35.21% examples, 1432463 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:25,948 : INFO : EPOCH 30 - PROGRESS: at 52.49% examples, 1424318 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:26,961 : INFO : EPOCH 30 - PROGRESS: at 70.01% examples, 1422403 words/s, in_qsize 12, out_qsize 1\n",
      "2020-06-05 13:54:27,975 : INFO : EPOCH 30 - PROGRESS: at 87.27% examples, 1416864 words/s, in_qsize 13, out_qsize 0\n",
      "2020-06-05 13:54:28,661 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-05 13:54:28,667 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-05 13:54:28,669 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-05 13:54:28,674 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-05 13:54:28,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-05 13:54:28,684 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-05 13:54:28,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-05 13:54:28,687 : INFO : EPOCH - 30 : training on 9140124 raw words (8192013 effective words) took 5.8s, 1422687 effective words/s\n",
      "2020-06-05 13:54:28,688 : INFO : training on a 274203720 raw words (245788241 effective words) took 167.4s, 1468323 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245788241, 274203720)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(documents, total_examples=w2v_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby zweryfikować jego działanie możemy wypisać podobne znaczeniowo słowa do danego wyrazu. Jeśli faktycznie będę podobne oznacza to, że mają one podobną reprezentację wektorową w naszym modelu - co chcieliśmy osiągnąć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sentimental140/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-06-05 13:54:35,760 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puppy', 0.6332559585571289),\n",
       " ('cat', 0.6248475313186646),\n",
       " ('dogs', 0.6020611524581909),\n",
       " ('pup', 0.5633569955825806),\n",
       " ('doggy', 0.5555011630058289),\n",
       " ('doggie', 0.5480417013168335),\n",
       " ('kitten', 0.5437886118888855),\n",
       " ('kitty', 0.5385284423828125),\n",
       " ('yorkie', 0.494467556476593),\n",
       " ('beagle', 0.49058279395103455)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sentimental140/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dog', 0.6248475909233093),\n",
       " ('kitten', 0.5832688808441162),\n",
       " ('kitty', 0.5827884674072266),\n",
       " ('cats', 0.5259411334991455),\n",
       " ('kittens', 0.48069098591804504),\n",
       " ('puppy', 0.47000187635421753),\n",
       " ('stray', 0.45526397228240967),\n",
       " ('pug', 0.43060335516929626),\n",
       " ('meowing', 0.4295699894428253),\n",
       " ('litter', 0.42768192291259766)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zapisywanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odpowiedź dawane przez nasz model wyglądają dobrze. Dlatego też możemy zoptymalizować i zapisać nasz model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-05 14:12:20,772 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-06-05 14:12:20,808 : INFO : saving Word2Vec object under W2V.model, separately None\n",
      "2020-06-05 14:12:20,809 : INFO : not storing attribute vectors_norm\n",
      "2020-06-05 14:12:20,810 : INFO : not storing attribute cum_table\n",
      "2020-06-05 14:12:21,359 : INFO : saved W2V.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace = True)\n",
    "w2v_model.save(W2V_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapiszmy jednocześnie nasz model w formie `pickla`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(PREPROCESSED_TRAIN_PATH)\n",
    "df_test.to_pickle(PREPROCESSED_TEST_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('sentimental140': conda)",
   "language": "python",
   "name": "python37664bitsentimental140conda07d71989f6da4b19a7e739dae5b254da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
