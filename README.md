# ğŸ˜„ğŸ˜ğŸ˜¡ Analiza sentymentu na podstawie [Sentimental140](http://help.sentiment140.com/for-students)

## ğŸ“ Cel projektu

Celem projektu byÅ‚o stworznie module, ktÃ³ry byÅ‚by w stanie na podstawie tekstu odczytaÄ‡ emocje z niego pÅ‚ynÄ…ce. Innymi sÅ‚owy, czy tekst ma zabarwienie pozytywne czy negatywne.

## ğŸ— Testowane architektury

- `SVM` z jÄ…drem `rbf` korzystajÄ…cy z rÃ³Å¼nych parametrÃ³w. Najlepsza konfiguracja zostaÅ‚a odnaleziona za pomocÄ… algorytmu `grid search`.
- Trzy rÃ³Å¼ne modele sieci neuronowych korzystajÄ…ce z `LSTM`:
  - **`LSTM_V1`**
  ```
  Layer (type)                 Output Shape              Param #
  =================================================================
  embedding_1 (Embedding)      (None, 50, 300)           73362000
  _________________________________________________________________
  dropout_1 (Dropout)          (None, 50, 300)           0
  _________________________________________________________________
  lstm_1 (LSTM)                (None, 100)               160400
  _________________________________________________________________
  dense_1 (Dense)              (None, 1)                 101
  =================================================================
  Total params: 73,522,501
  Trainable params: 160,501
  Non-trainable params: 73,362,000
  _________________________________________________________________
  ```
  - **`LSTM_V2`**
  ```
  Layer (type)                 Output Shape              Param #
  =================================================================
  embedding_2 (Embedding)      (None, 50, 300)           73362000
  _________________________________________________________________
  spatial_dropout1d_1 (Spatial (None, 50, 300)           0
  _________________________________________________________________
  conv1d_1 (Conv1D)            (None, 46, 64)            96064
  _________________________________________________________________
  bidirectional_1 (Bidirection (None, 128)               66048
  _________________________________________________________________
  dense_2 (Dense)              (None, 512)               66048
  _________________________________________________________________
  dropout_2 (Dropout)          (None, 512)               0
  _________________________________________________________________
  dense_3 (Dense)              (None, 512)               262656
  _________________________________________________________________
  dense_4 (Dense)              (None, 1)                 513
  =================================================================
  Total params: 73,853,329
  Trainable params: 491,329
  Non-trainable params: 73,362,000
  _________________________________________________________________
  ```
  - **`LSTM_V3`**
  ```
  Layer (type)                 Output Shape              Param #
  =================================================================
  embedding_3 (Embedding)      (None, 50, 32)            7825280
  _________________________________________________________________
  spatial_dropout1d_2 (Spatial (None, 50, 32)            0
  _________________________________________________________________
  lstm_3 (LSTM)                (None, 50)                16600
  _________________________________________________________________
  dropout_3 (Dropout)          (None, 50)                0
  _________________________________________________________________
  dense_5 (Dense)              (None, 1)                 51
  =================================================================
  Total params: 7,841,931
  Trainable params: 7,841,931
  Non-trainable params: 0
  _________________________________________________________________
  ```
  Z czego dwa pierwsze korzystajÄ…c z modelu `word2vec`, ktÃ³ry zostaÅ‚ wczeÅ›niej na danych wejÅ›ciowych. Natomiast trzeci model uczy siÄ™ embeddingu na bieÅ¼Ä…co.

## âš™ï¸ ZawartoÅ›Ä‡ projektu

- [preprocessing](https://github.com/lukmccall/psi-project/blob/master/preprocessing.ipynb) skrypt opisujÄ…cy proces oczyszczania danych oraz uczenia modelu `word2vec`. NaleÅ¼y wykonaÄ‡ go na poczÄ…tku.
- [svm](https://github.com/lukmccall/psi-project/blob/master/svm.ipynb) skrypt tworzÄ…cy i uczÄ…cy model `SVM` pochadzÄ…cy z `sklearn`. Uczenie go zajmie bardzo duÅ¼o czasu. Dlatego teÅ¼, zalecam zmiejeszenie danych wejÅ›ciowych przy testowaniu programu.
- [neural_network](https://github.com/lukmccall/psi-project/blob/master/neural_network.ipynb) skrypt tworzÄ…cy i uczÄ…cy trzy modele sieci rekurencyjnych z biblioteki `TensorFlow` z wykorzystaniem `Kerasa`. Tak samo jak w przypadku `SVM'a` proces ten jest czasochÅ‚onny. Zalecane jest uczenie na karcie graficznej a nie na procesorze. W skrypcie znajduje siÄ™ informacja z jakiej jednoski liczÄ…cej korzysta program.
- [summary](https://github.com/lukmccall/psi-project/blob/master/summary.ipynb) skrypt zbierajÄ…cy i prezentujÄ…cy wyniki wszystkich 4 modeli. Na koÅ„cu zaprezentowane jest rÃ³wnieÅ¼ dziaÅ‚anie algorytmy `word2vec`.

## ğŸ•µï¸â€â™‚ï¸ PorÃ³wnanie wynikÃ³w

![roc_curve](result.png)

Na powyÅ¼szym rysunku znajduje siÄ™ wykres porÃ³wnujÄ…cy wszystkie 4 modele. Åatwo moÅ¼emy zauwaÅ¼yÄ‡, Å¼e algorytm oznaczony jako **`LSTM_V1`** sprawdza siÄ™ najlepiej. Bardziej szczegÃ³Å‚owa analiza znajduje siÄ™ w pliku [summary](https://github.com/lukmccall/psi-project/blob/master/summary.ipynb).

## ğŸš€ Jak uruchomiÄ‡ projekt

1. Sklonuj reposytorium

   ```sh
   $ git clone https://github.com/lukmccall/psi-project.git
   ```

2. Pobierz plik z danymi z strony http://help.sentiment140.com/for-students i umieÅ›Ä‡ go w folderze projektu.

3. Upewnij siÄ™, Å¼e masz zainstalowÄ… [Anaconde](anaconda.com).

4. W folderze projektu uruchmÄ… nastÄ™pujÄ…ce komendy:

   ```sh
   $ conda env create -f enviroment.yml
   $ conda activate sentimental140
   $ jupyter notebook
   ```

5. Otworzy Ci siÄ™ przeglÄ…darka, gdzie bÄ™dziesz mÃ³gÅ‚ wybraÄ‡Â odpowiedni skrypt. PamiÄ™taj, Å¼e na poczÄ…tku musisz odtworzyÄ‡ i wykonaÄ‡ plik [preprocessing](https://github.com/lukmccall/psi-project/blob/master/preprocessing.ipynb). Stworzy on na dysku model `word2vec` oraz wyczyszczone dane.
